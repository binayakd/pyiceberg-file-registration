{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfda232-5c35-4af0-8767-f8eb9efdb49a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In my [last post](https://binayakd.tech/posts/2024-08-30-exploring-iceberg/), I explored the fundamentals of how to create Apache Iceberg tables, using various catalogs, and how to use Spark and Trino to write and read data into and from these Iceberg tables. That involved using Spark as the the Iceberg client to write data into Iceberg table. \n",
    "\n",
    "However, in the case that data is already in object storage, following this process to create Iceberg tables, would involve a full migration (read, write, delete) of the data, which can prove time consuming and costly for large datasets. \n",
    "\n",
    "What we need is a workflow similar to [Hive's External tables](https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables), where writing and updating of the data is managed by an external process (or managed by a preexisting pipeline), and the Iceberg tables is the metadata layer, allowing querying of the data. \n",
    "\n",
    "This very problem has been addressed before in [this article](https://medium.com/inquery-data/registering-s3-files-into-apache-iceberg-tables-without-the-rewrites-3c087cb01658). However, that article used the Iceberg Java APIs, and is over one year old as of writing this, and proved to be somewhat cumbersome. \n",
    "\n",
    "Fortunately Pyiceberg, has come to the rescue to provide a more straightforward way to achieve this. Specifically, we can use the [`add_files`](https://py.iceberg.apache.org/api/#add-fields) method to register parquet files to a Iceberg table without rewrites. \n",
    "\n",
    "In this post, I will be essentially be following the Pyiceberg [Getting started tutorial](https://py.iceberg.apache.org/) with the difference being, I will being using Minio as the object storage, and using the `add_files` function, instead of appending (writing) the data.\n",
    "\n",
    "For this we need to setup Minio, and and Postgres as the backend for the Iceberg SQL catalog, which we can conveniently setup using a Docker compose file (found in this repo). You can of courses also just use files in local file system, and SQLite backed catalog, but that does not properly show the benefits of this workflow, which is to be able to migrate existing data in object storage to Iceberg format, without doing expensive rewrites. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e87665",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To work though this Notebook demo, you would need the following installed:\n",
    "\n",
    "1. Docker/Podman Compose\n",
    "2. Python 3.12 or higher\n",
    "3. uv Python project manager (optional)\n",
    "2. Minio client (optional)\n",
    "\n",
    "There is a docker compose file in this repo, that will start the Postgres and Minio instances, and also run an Minio client container to create the `warehouse` bucket in the Minio instance. Here I will be using Podman:\n",
    "```bash\n",
    "podman compose up\n",
    "```\n",
    "\n",
    "The actual data for Minio and Postgres will be stored in the `local-data` folder, in the respective folders.\n",
    "\n",
    "Python 3.12 and uv package manage was used for this demo. So the dependencies are setup in the `pyproject.toml` and `uv.lock` file. To get started using uv, first create the python virtual environment and install the required dependencies (has to be run outside this notebook):\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "Then start the Jupyter Lab server using this virtual environment:\n",
    "\n",
    "```bash\n",
    "uv run --with jupyter jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f1987",
   "metadata": {},
   "source": [
    "## Test data setup\n",
    "We will be using the classic NYC Taxi datasets for these tests. So we download the set for January 2024, save it to our local filesystem, in the test-data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 47.6M  100 47.6M    0     0  4217k      0  0:00:11  0:00:11 --:--:-- 5225k\n"
     ]
    }
   ],
   "source": [
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet -o ./local-data/test-data/yellow_tripdata_2024-01.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0d6ca",
   "metadata": {},
   "source": [
    "Then we will simulate a data generation process, such as ELT pipeline to upload our Minio instance. In this demo, we also need to do some modifications to the raw data, for the the `add_files` functions to work. We will use Polars to do this here, but we can just as easily be using something like Spark or Pandas. \n",
    "\n",
    "First read the file from local file system into a polars dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a34e21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(900)\n",
    "pl.Config.set_tbl_width_chars(900)\n",
    "\n",
    "df = pl.read_parquet(\"./local-data/test-data/yellow_tripdata_2024-01.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4912fa0",
   "metadata": {},
   "source": [
    "We now need to convert downcast the nanosecond timestamp columns into microsecond, as PyIceberg only supports down to microseconds. There is a mechanism for PyIceberg to help us to do the casting automatically using a [configurations or environment variable](https://py.iceberg.apache.org/configuration/#nanoseconds-support), however this only works if we are writing to the Iceberg table directly, instead of adding existing files. \n",
    "\n",
    "Thus this has to be done manually. We first check which columns need casting by getting the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a77b2724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('VendorID', Int32),\n",
       "        ('tpep_pickup_datetime', Datetime(time_unit='ns', time_zone=None)),\n",
       "        ('tpep_dropoff_datetime', Datetime(time_unit='ns', time_zone=None)),\n",
       "        ('passenger_count', Int64),\n",
       "        ('trip_distance', Float64),\n",
       "        ('RatecodeID', Int64),\n",
       "        ('store_and_fwd_flag', String),\n",
       "        ('PULocationID', Int32),\n",
       "        ('DOLocationID', Int32),\n",
       "        ('payment_type', Int64),\n",
       "        ('fare_amount', Float64),\n",
       "        ('extra', Float64),\n",
       "        ('mta_tax', Float64),\n",
       "        ('tip_amount', Float64),\n",
       "        ('tolls_amount', Float64),\n",
       "        ('improvement_surcharge', Float64),\n",
       "        ('total_amount', Float64),\n",
       "        ('congestion_surcharge', Float64),\n",
       "        ('Airport_fee', Float64)])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd1766",
   "metadata": {},
   "source": [
    "From here we see that columns `tpep_pickup_datetime` and `tpep_dropoff_datetime` are of type `Datatime` with time unit \"ns\". So those are what needs to be casted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5cfa1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.col(\"tpep_pickup_datetime\").dt.cast_time_unit(\"ms\"))\n",
    "df = df.with_columns(pl.col(\"tpep_dropoff_datetime\").dt.cast_time_unit(\"ms\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743de7bd",
   "metadata": {},
   "source": [
    "We check the schema again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1dd10c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('VendorID', Int32),\n",
       "        ('tpep_pickup_datetime', Datetime(time_unit='ms', time_zone=None)),\n",
       "        ('tpep_dropoff_datetime', Datetime(time_unit='ms', time_zone=None)),\n",
       "        ('passenger_count', Int64),\n",
       "        ('trip_distance', Float64),\n",
       "        ('RatecodeID', Int64),\n",
       "        ('store_and_fwd_flag', String),\n",
       "        ('PULocationID', Int32),\n",
       "        ('DOLocationID', Int32),\n",
       "        ('payment_type', Int64),\n",
       "        ('fare_amount', Float64),\n",
       "        ('extra', Float64),\n",
       "        ('mta_tax', Float64),\n",
       "        ('tip_amount', Float64),\n",
       "        ('tolls_amount', Float64),\n",
       "        ('improvement_surcharge', Float64),\n",
       "        ('total_amount', Float64),\n",
       "        ('congestion_surcharge', Float64),\n",
       "        ('Airport_fee', Float64)])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa0850",
   "metadata": {},
   "source": [
    "There is one more update we need to do to the data. In my [previous post](https://binayakd.tech/posts/2024-08-30-exploring-iceberg/#writing-the-data-to-iceberg-table), we found out that although this file is marked for 2024-01, it actually has some stray data from some other months. We need to remove those extra month's data, as this will cause issues when we try to add this file to the Iceberg table partitioned by month. \n",
    "\n",
    "This is because, since adding files does not modify the actual files, the process will not be able to split the files into the different partitioned parquet files, and also can't add a single file to multiple partitions.\n",
    "\n",
    "So we can use polars to do this filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5df7ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\n",
    "    (pl.col(\"tpep_pickup_datetime\").dt.year() == 2024) & (pl.col(\"tpep_pickup_datetime\").dt.month() == 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c23b57",
   "metadata": {},
   "source": [
    "And we check if the filtering worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "199f7df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th></tr><tr><td>i32</td><td>i8</td></tr></thead><tbody><tr><td>2024</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌──────┬───────┐\n",
       "│ year ┆ month │\n",
       "│ ---  ┆ ---   │\n",
       "│ i32  ┆ i8    │\n",
       "╞══════╪═══════╡\n",
       "│ 2024 ┆ 1     │\n",
       "└──────┴───────┘"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df\n",
    " .with_columns(pl.col(\"tpep_pickup_datetime\").dt.year().alias(\"year\"))\n",
    " .with_columns(pl.col(\"tpep_pickup_datetime\").dt.month().alias(\"month\"))\n",
    " .unique(subset=[\"year\", \"month\"])\n",
    " .select(['year', 'month'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eeed56",
   "metadata": {},
   "source": [
    "We can now write it into Minio. For that, we first setup the storage options for Minio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6083cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "conn_data = { \n",
    "    'key': 'admin', \n",
    "    'secret': 'password', \n",
    "    'client_kwargs': { \n",
    "        'endpoint_url': 'http://localhost:9000' \n",
    "        }\n",
    "}\n",
    "s3_fs = s3fs.S3FileSystem(**conn_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daab0c7",
   "metadata": {},
   "source": [
    "And finally write it to our desired bucket and location, with statistics enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f902e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://warehouse/data/yellow_tripdata_2024-01.parquet\"\n",
    "\n",
    "with s3_fs.open(s3_path, \"wb\") as f:\n",
    "    df.write_parquet(f, statistics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cba0f4",
   "metadata": {},
   "source": [
    "## Creating an SQL Catalog\n",
    "As mentioned, we will be creating an SQL catalog, using the Postgres instance as the DB backend. We also include the Minio connection details for the Warehouse location. This should correspond to the object storage instance that contains the preexisting files we want to add to the Iceberg tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "catalog = SqlCatalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"uri\": \"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\",\n",
    "        \"warehouse\": \"s3://warehouse/iceberg\",\n",
    "        \"s3.endpoint\": \"http://localhost:9000\",\n",
    "        \"s3.access-key-id\": \"admin\",\n",
    "        \"s3.secret-access-key\": \"password\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d5af1a",
   "metadata": {},
   "source": [
    "## Creating the Iceberg Table\n",
    "\n",
    "Now that we have our catalog setup, we need to first create the table, with a defined schema. \n",
    "This schema can be gotten from the Parquet file directly, using PyArrow. \n",
    "\n",
    "First we create a filesystem object to let Pyarrow know how to connect to Minio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60538e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pyarrow import fs\n",
    "\n",
    "\n",
    "minio = fs.S3FileSystem(\n",
    "    endpoint_override='localhost:9000',\n",
    "    access_key=\"admin\",\n",
    "    secret_key=\"password\",\n",
    "    scheme=\"http\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4898c",
   "metadata": {},
   "source": [
    "Then we read the file as a PyArrow table from the specific bucket and path, and the Minio filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "175d88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table(\n",
    "    \"warehouse/data/yellow_tripdata_2024-01.parquet\",\n",
    "    filesystem=minio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c9526",
   "metadata": {},
   "source": [
    "We can check what the schema actually looks like, to ensure its matches to what we wrote before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "406fcf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID: int32\n",
       "tpep_pickup_datetime: timestamp[ms]\n",
       "tpep_dropoff_datetime: timestamp[ms]\n",
       "passenger_count: int64\n",
       "trip_distance: double\n",
       "RatecodeID: int64\n",
       "store_and_fwd_flag: large_string\n",
       "PULocationID: int32\n",
       "DOLocationID: int32\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "Airport_fee: double"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ad678",
   "metadata": {},
   "source": [
    "We now have enough setup to create the namespace and table.\n",
    "\n",
    "Creating the namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03e1e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace(\"nyc_taxi_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca495195",
   "metadata": {},
   "source": [
    "And then the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9f4e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.create_table(\n",
    "    \"nyc_taxi_data.yellow_tripdata\",\n",
    "    schema=df.schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a1150",
   "metadata": {},
   "source": [
    "Now we add the partition field (column) by using `MonthTransform` on the `tpep_pickup_datetime` column, to have the data partitioned by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cd028d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.transforms import MonthTransform\n",
    "\n",
    "with table.update_spec() as update_spec:\n",
    "    update_spec.add_field(\n",
    "        source_column_name=\"tpep_pickup_datetime\",\n",
    "        transform=MonthTransform(),\n",
    "        partition_field_name=\"tpep_pickup_datetime_month\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc1b89",
   "metadata": {},
   "source": [
    "## Adding Parquet File to Table\n",
    "\n",
    "Now that we have created the table, with the partition fields, we can finally add the parquet file to the table. First we reload the table reference by the table name, just in case we need to re-run this, as `create_table` method cannot be run multiple time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1843be0-415e-4507-ad49-e7e55966e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.load_table(\"nyc_taxi_data.yellow_tripdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfcdf5",
   "metadata": {},
   "source": [
    "Now we use the `add_files` method to add the file. Since this method takes in a list, we have to setup the list with our one file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a78467a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add_files([\"s3://warehouse/data/yellow_tripdata_2024-01.parquet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ff138",
   "metadata": {},
   "source": [
    "Now we can try and query it back using polars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "08d12e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_964_606, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th></tr><tr><td>i32</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2024-01-01 00:57:55</td><td>2024-01-01 01:17:43</td><td>1</td><td>1.72</td><td>1</td><td>&quot;N&quot;</td><td>186</td><td>79</td><td>2</td><td>17.7</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.7</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:03:00</td><td>2024-01-01 00:09:36</td><td>1</td><td>1.8</td><td>1</td><td>&quot;N&quot;</td><td>140</td><td>236</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>3.75</td><td>0.0</td><td>1.0</td><td>18.75</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:17:06</td><td>2024-01-01 00:35:01</td><td>1</td><td>4.7</td><td>1</td><td>&quot;N&quot;</td><td>236</td><td>79</td><td>1</td><td>23.3</td><td>3.5</td><td>0.5</td><td>3.0</td><td>0.0</td><td>1.0</td><td>31.3</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:36:38</td><td>2024-01-01 00:44:56</td><td>1</td><td>1.4</td><td>1</td><td>&quot;N&quot;</td><td>79</td><td>211</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>17.0</td><td>2.5</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:46:51</td><td>2024-01-01 00:52:57</td><td>1</td><td>0.8</td><td>1</td><td>&quot;N&quot;</td><td>211</td><td>148</td><td>1</td><td>7.9</td><td>3.5</td><td>0.5</td><td>3.2</td><td>0.0</td><td>1.0</td><td>16.1</td><td>2.5</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>2024-01-31 23:45:59</td><td>2024-01-31 23:54:36</td><td>null</td><td>3.18</td><td>null</td><td>null</td><td>107</td><td>263</td><td>0</td><td>15.77</td><td>0.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>21.77</td><td>null</td><td>null</td></tr><tr><td>1</td><td>2024-01-31 23:13:07</td><td>2024-01-31 23:27:52</td><td>null</td><td>4.0</td><td>null</td><td>null</td><td>114</td><td>236</td><td>0</td><td>18.4</td><td>1.0</td><td>0.5</td><td>2.34</td><td>0.0</td><td>1.0</td><td>25.74</td><td>null</td><td>null</td></tr><tr><td>2</td><td>2024-01-31 23:19:00</td><td>2024-01-31 23:38:00</td><td>null</td><td>3.33</td><td>null</td><td>null</td><td>211</td><td>25</td><td>0</td><td>19.97</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.97</td><td>null</td><td>null</td></tr><tr><td>2</td><td>2024-01-31 23:07:23</td><td>2024-01-31 23:25:14</td><td>null</td><td>3.06</td><td>null</td><td>null</td><td>107</td><td>13</td><td>0</td><td>23.88</td><td>0.0</td><td>0.5</td><td>5.58</td><td>0.0</td><td>1.0</td><td>33.46</td><td>null</td><td>null</td></tr><tr><td>1</td><td>2024-01-31 23:58:25</td><td>2024-02-01 00:13:30</td><td>null</td><td>8.1</td><td>null</td><td>null</td><td>138</td><td>75</td><td>0</td><td>32.4</td><td>7.75</td><td>0.5</td><td>7.29</td><td>6.94</td><td>1.0</td><td>55.88</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_964_606, 19)\n",
       "┌──────────┬──────────────────────┬───────────────────────┬─────────────────┬───┬───────────────────────┬──────────────┬──────────────────────┬─────────────┐\n",
       "│ VendorID ┆ tpep_pickup_datetime ┆ tpep_dropoff_datetime ┆ passenger_count ┆ … ┆ improvement_surcharge ┆ total_amount ┆ congestion_surcharge ┆ Airport_fee │\n",
       "│ ---      ┆ ---                  ┆ ---                   ┆ ---             ┆   ┆ ---                   ┆ ---          ┆ ---                  ┆ ---         │\n",
       "│ i32      ┆ datetime[μs]         ┆ datetime[μs]          ┆ i64             ┆   ┆ f64                   ┆ f64          ┆ f64                  ┆ f64         │\n",
       "╞══════════╪══════════════════════╪═══════════════════════╪═════════════════╪═══╪═══════════════════════╪══════════════╪══════════════════════╪═════════════╡\n",
       "│ 2        ┆ 2024-01-01 00:57:55  ┆ 2024-01-01 01:17:43   ┆ 1               ┆ … ┆ 1.0                   ┆ 22.7         ┆ 2.5                  ┆ 0.0         │\n",
       "│ 1        ┆ 2024-01-01 00:03:00  ┆ 2024-01-01 00:09:36   ┆ 1               ┆ … ┆ 1.0                   ┆ 18.75        ┆ 2.5                  ┆ 0.0         │\n",
       "│ 1        ┆ 2024-01-01 00:17:06  ┆ 2024-01-01 00:35:01   ┆ 1               ┆ … ┆ 1.0                   ┆ 31.3         ┆ 2.5                  ┆ 0.0         │\n",
       "│ 1        ┆ 2024-01-01 00:36:38  ┆ 2024-01-01 00:44:56   ┆ 1               ┆ … ┆ 1.0                   ┆ 17.0         ┆ 2.5                  ┆ 0.0         │\n",
       "│ 1        ┆ 2024-01-01 00:46:51  ┆ 2024-01-01 00:52:57   ┆ 1               ┆ … ┆ 1.0                   ┆ 16.1         ┆ 2.5                  ┆ 0.0         │\n",
       "│ …        ┆ …                    ┆ …                     ┆ …               ┆ … ┆ …                     ┆ …            ┆ …                    ┆ …           │\n",
       "│ 2        ┆ 2024-01-31 23:45:59  ┆ 2024-01-31 23:54:36   ┆ null            ┆ … ┆ 1.0                   ┆ 21.77        ┆ null                 ┆ null        │\n",
       "│ 1        ┆ 2024-01-31 23:13:07  ┆ 2024-01-31 23:27:52   ┆ null            ┆ … ┆ 1.0                   ┆ 25.74        ┆ null                 ┆ null        │\n",
       "│ 2        ┆ 2024-01-31 23:19:00  ┆ 2024-01-31 23:38:00   ┆ null            ┆ … ┆ 1.0                   ┆ 23.97        ┆ null                 ┆ null        │\n",
       "│ 2        ┆ 2024-01-31 23:07:23  ┆ 2024-01-31 23:25:14   ┆ null            ┆ … ┆ 1.0                   ┆ 33.46        ┆ null                 ┆ null        │\n",
       "│ 1        ┆ 2024-01-31 23:58:25  ┆ 2024-02-01 00:13:30   ┆ null            ┆ … ┆ 1.0                   ┆ 55.88        ┆ null                 ┆ null        │\n",
       "└──────────┴──────────────────────┴───────────────────────┴─────────────────┴───┴───────────────────────┴──────────────┴──────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.scan_iceberg(table).collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914a9a1",
   "metadata": {},
   "source": [
    "Taking a look at the data in Minio, we can see 3 metadata log entries being created, the first for creating the table, the second for adding the partition filed, and the third for actually using `add_files` to append the data files to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f5ddf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>file</th><th>latest_snapshot_id</th><th>latest_schema_id</th><th>latest_sequence_number</th></tr><tr><td>datetime[ms]</td><td>str</td><td>i64</td><td>i32</td><td>i64</td></tr></thead><tbody><tr><td>2024-12-19 05:48:20.761</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00000-8ee1e9ab-902e-426d-aa60-e7cf1a5a40ed.metadata.json&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2024-12-19 05:48:24.354</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00001-c79b1499-524e-4cea-b46a-fb793ab14b78.metadata.json&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2024-12-19 05:48:35.092</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00002-02dfa0f2-6d50-4275-85b3-5fa601ba6d37.metadata.json&quot;</td><td>1266899188045554572</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌─────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─────────────────────┬──────────────────┬────────────────────────┐\n",
       "│ timestamp               ┆ file                                                                                                                      ┆ latest_snapshot_id  ┆ latest_schema_id ┆ latest_sequence_number │\n",
       "│ ---                     ┆ ---                                                                                                                       ┆ ---                 ┆ ---              ┆ ---                    │\n",
       "│ datetime[ms]            ┆ str                                                                                                                       ┆ i64                 ┆ i32              ┆ i64                    │\n",
       "╞═════════════════════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪═════════════════════╪══════════════════╪════════════════════════╡\n",
       "│ 2024-12-19 05:48:20.761 ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00000-8ee1e9ab-902e-426d-aa60-e7cf1a5a40ed.metadata.json ┆ null                ┆ null             ┆ null                   │\n",
       "│ 2024-12-19 05:48:24.354 ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00001-c79b1499-524e-4cea-b46a-fb793ab14b78.metadata.json ┆ null                ┆ null             ┆ null                   │\n",
       "│ 2024-12-19 05:48:35.092 ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/00002-02dfa0f2-6d50-4275-85b3-5fa601ba6d37.metadata.json ┆ 1266899188045554572 ┆ 0                ┆ 1                      │\n",
       "└─────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┴──────────────────┴────────────────────────┘"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(table.inspect.metadata_log_entries())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244b959",
   "metadata": {},
   "source": [
    "Taking a look at the snapshots, we see the one created when the `add_files` operation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "47bdf67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>committed_at</th><th>snapshot_id</th><th>parent_id</th><th>operation</th><th>manifest_list</th><th>summary</th></tr><tr><td>datetime[ms]</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>list[struct[2]]</td></tr></thead><tbody><tr><td>2024-12-19 05:48:35.092</td><td>1266899188045554572</td><td>null</td><td>&quot;append&quot;</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-1266899188045554572-0-f40953b3-d76b-490e-8e14-3341ef82477c.avro&quot;</td><td>[{&quot;added-files-size&quot;,&quot;55387088&quot;}, {&quot;added-data-files&quot;,&quot;1&quot;}, … {&quot;total-equality-deletes&quot;,&quot;0&quot;}]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "┌─────────────────────────┬─────────────────────┬───────────┬───────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ committed_at            ┆ snapshot_id         ┆ parent_id ┆ operation ┆ manifest_list                                                                                                                         ┆ summary                                                                                       │\n",
       "│ ---                     ┆ ---                 ┆ ---       ┆ ---       ┆ ---                                                                                                                                   ┆ ---                                                                                           │\n",
       "│ datetime[ms]            ┆ i64                 ┆ i64       ┆ str       ┆ str                                                                                                                                   ┆ list[struct[2]]                                                                               │\n",
       "╞═════════════════════════╪═════════════════════╪═══════════╪═══════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════════════════════════════════════════════════════════════════════════════════╡\n",
       "│ 2024-12-19 05:48:35.092 ┆ 1266899188045554572 ┆ null      ┆ append    ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-1266899188045554572-0-f40953b3-d76b-490e-8e14-3341ef82477c.avro ┆ [{\"added-files-size\",\"55387088\"}, {\"added-data-files\",\"1\"}, … {\"total-equality-deletes\",\"0\"}] │\n",
       "└─────────────────────────┴─────────────────────┴───────────┴───────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(table.inspect.snapshots())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30657cbb",
   "metadata": {},
   "source": [
    "Taking a look at the list of files for this table, we can see the file we added is listed, from the path we wrote directly, with no rewrites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c9a16991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>file_path</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;s3://warehouse/data/yellow_tripdata_2024-01.parquet&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────────────────────────────────────────────────────┐\n",
       "│ file_path                                           │\n",
       "│ ---                                                 │\n",
       "│ str                                                 │\n",
       "╞═════════════════════════════════════════════════════╡\n",
       "│ s3://warehouse/data/yellow_tripdata_2024-01.parquet │\n",
       "└─────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(table.inspect.files()).select(\"file_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993006e",
   "metadata": {},
   "source": [
    "Now lets what happens if we do try to update the existing data though Iceberg. Following the PyIceberg \"Getting Started\" tutorial, we compute and tip-per-mile. First we use polars to compute this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "710871c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_964_606, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th><th>tip_per_mile</th></tr><tr><td>i32</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2024-01-01 00:57:55</td><td>2024-01-01 01:17:43</td><td>1</td><td>1.72</td><td>1</td><td>&quot;N&quot;</td><td>186</td><td>79</td><td>2</td><td>17.7</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.7</td><td>2.5</td><td>0.0</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:03:00</td><td>2024-01-01 00:09:36</td><td>1</td><td>1.8</td><td>1</td><td>&quot;N&quot;</td><td>140</td><td>236</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>3.75</td><td>0.0</td><td>1.0</td><td>18.75</td><td>2.5</td><td>0.0</td><td>2.083333</td></tr><tr><td>1</td><td>2024-01-01 00:17:06</td><td>2024-01-01 00:35:01</td><td>1</td><td>4.7</td><td>1</td><td>&quot;N&quot;</td><td>236</td><td>79</td><td>1</td><td>23.3</td><td>3.5</td><td>0.5</td><td>3.0</td><td>0.0</td><td>1.0</td><td>31.3</td><td>2.5</td><td>0.0</td><td>0.638298</td></tr><tr><td>1</td><td>2024-01-01 00:36:38</td><td>2024-01-01 00:44:56</td><td>1</td><td>1.4</td><td>1</td><td>&quot;N&quot;</td><td>79</td><td>211</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>17.0</td><td>2.5</td><td>0.0</td><td>1.428571</td></tr><tr><td>1</td><td>2024-01-01 00:46:51</td><td>2024-01-01 00:52:57</td><td>1</td><td>0.8</td><td>1</td><td>&quot;N&quot;</td><td>211</td><td>148</td><td>1</td><td>7.9</td><td>3.5</td><td>0.5</td><td>3.2</td><td>0.0</td><td>1.0</td><td>16.1</td><td>2.5</td><td>0.0</td><td>4.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>2024-01-31 23:45:59</td><td>2024-01-31 23:54:36</td><td>null</td><td>3.18</td><td>null</td><td>null</td><td>107</td><td>263</td><td>0</td><td>15.77</td><td>0.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>21.77</td><td>null</td><td>null</td><td>0.628931</td></tr><tr><td>1</td><td>2024-01-31 23:13:07</td><td>2024-01-31 23:27:52</td><td>null</td><td>4.0</td><td>null</td><td>null</td><td>114</td><td>236</td><td>0</td><td>18.4</td><td>1.0</td><td>0.5</td><td>2.34</td><td>0.0</td><td>1.0</td><td>25.74</td><td>null</td><td>null</td><td>0.585</td></tr><tr><td>2</td><td>2024-01-31 23:19:00</td><td>2024-01-31 23:38:00</td><td>null</td><td>3.33</td><td>null</td><td>null</td><td>211</td><td>25</td><td>0</td><td>19.97</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.97</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>2</td><td>2024-01-31 23:07:23</td><td>2024-01-31 23:25:14</td><td>null</td><td>3.06</td><td>null</td><td>null</td><td>107</td><td>13</td><td>0</td><td>23.88</td><td>0.0</td><td>0.5</td><td>5.58</td><td>0.0</td><td>1.0</td><td>33.46</td><td>null</td><td>null</td><td>1.823529</td></tr><tr><td>1</td><td>2024-01-31 23:58:25</td><td>2024-02-01 00:13:30</td><td>null</td><td>8.1</td><td>null</td><td>null</td><td>138</td><td>75</td><td>0</td><td>32.4</td><td>7.75</td><td>0.5</td><td>7.29</td><td>6.94</td><td>1.0</td><td>55.88</td><td>null</td><td>null</td><td>0.9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_964_606, 20)\n",
       "┌──────────┬──────────────────────┬───────────────────────┬─────────────────┬───┬──────────────┬──────────────────────┬─────────────┬──────────────┐\n",
       "│ VendorID ┆ tpep_pickup_datetime ┆ tpep_dropoff_datetime ┆ passenger_count ┆ … ┆ total_amount ┆ congestion_surcharge ┆ Airport_fee ┆ tip_per_mile │\n",
       "│ ---      ┆ ---                  ┆ ---                   ┆ ---             ┆   ┆ ---          ┆ ---                  ┆ ---         ┆ ---          │\n",
       "│ i32      ┆ datetime[μs]         ┆ datetime[μs]          ┆ i64             ┆   ┆ f64          ┆ f64                  ┆ f64         ┆ f64          │\n",
       "╞══════════╪══════════════════════╪═══════════════════════╪═════════════════╪═══╪══════════════╪══════════════════════╪═════════════╪══════════════╡\n",
       "│ 2        ┆ 2024-01-01 00:57:55  ┆ 2024-01-01 01:17:43   ┆ 1               ┆ … ┆ 22.7         ┆ 2.5                  ┆ 0.0         ┆ 0.0          │\n",
       "│ 1        ┆ 2024-01-01 00:03:00  ┆ 2024-01-01 00:09:36   ┆ 1               ┆ … ┆ 18.75        ┆ 2.5                  ┆ 0.0         ┆ 2.083333     │\n",
       "│ 1        ┆ 2024-01-01 00:17:06  ┆ 2024-01-01 00:35:01   ┆ 1               ┆ … ┆ 31.3         ┆ 2.5                  ┆ 0.0         ┆ 0.638298     │\n",
       "│ 1        ┆ 2024-01-01 00:36:38  ┆ 2024-01-01 00:44:56   ┆ 1               ┆ … ┆ 17.0         ┆ 2.5                  ┆ 0.0         ┆ 1.428571     │\n",
       "│ 1        ┆ 2024-01-01 00:46:51  ┆ 2024-01-01 00:52:57   ┆ 1               ┆ … ┆ 16.1         ┆ 2.5                  ┆ 0.0         ┆ 4.0          │\n",
       "│ …        ┆ …                    ┆ …                     ┆ …               ┆ … ┆ …            ┆ …                    ┆ …           ┆ …            │\n",
       "│ 2        ┆ 2024-01-31 23:45:59  ┆ 2024-01-31 23:54:36   ┆ null            ┆ … ┆ 21.77        ┆ null                 ┆ null        ┆ 0.628931     │\n",
       "│ 1        ┆ 2024-01-31 23:13:07  ┆ 2024-01-31 23:27:52   ┆ null            ┆ … ┆ 25.74        ┆ null                 ┆ null        ┆ 0.585        │\n",
       "│ 2        ┆ 2024-01-31 23:19:00  ┆ 2024-01-31 23:38:00   ┆ null            ┆ … ┆ 23.97        ┆ null                 ┆ null        ┆ 0.0          │\n",
       "│ 2        ┆ 2024-01-31 23:07:23  ┆ 2024-01-31 23:25:14   ┆ null            ┆ … ┆ 33.46        ┆ null                 ┆ null        ┆ 1.823529     │\n",
       "│ 1        ┆ 2024-01-31 23:58:25  ┆ 2024-02-01 00:13:30   ┆ null            ┆ … ┆ 55.88        ┆ null                 ┆ null        ┆ 0.9          │\n",
       "└──────────┴──────────────────────┴───────────────────────┴─────────────────┴───┴──────────────┴──────────────────────┴─────────────┴──────────────┘"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "    (pl.col(\"tip_amount\")/pl.col(\"trip_distance\")).alias(\"tip_per_mile\")\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c0365",
   "metadata": {},
   "source": [
    "Convert the dataframe to an Arrow dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c668ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrow = df.to_arrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3130106",
   "metadata": {},
   "source": [
    "We then evolve the schema, to include this new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "47448a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with table.update_schema() as update_schema:\n",
    "    update_schema.union_by_name(df_arrow.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615f8c4",
   "metadata": {},
   "source": [
    "\n",
    "Then finally overwrite the Iceberg table with the new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b55a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.overwrite(df_arrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c88cba",
   "metadata": {},
   "source": [
    "Now checking on the table again, we should see the new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "925f7714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_964_606, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>Airport_fee</th><th>tip_per_mile</th></tr><tr><td>i32</td><td>datetime[μs]</td><td>datetime[μs]</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i32</td><td>i32</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>2024-01-01 00:57:55</td><td>2024-01-01 01:17:43</td><td>1</td><td>1.72</td><td>1</td><td>&quot;N&quot;</td><td>186</td><td>79</td><td>2</td><td>17.7</td><td>1.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.7</td><td>2.5</td><td>0.0</td><td>0.0</td></tr><tr><td>1</td><td>2024-01-01 00:03:00</td><td>2024-01-01 00:09:36</td><td>1</td><td>1.8</td><td>1</td><td>&quot;N&quot;</td><td>140</td><td>236</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>3.75</td><td>0.0</td><td>1.0</td><td>18.75</td><td>2.5</td><td>0.0</td><td>2.083333</td></tr><tr><td>1</td><td>2024-01-01 00:17:06</td><td>2024-01-01 00:35:01</td><td>1</td><td>4.7</td><td>1</td><td>&quot;N&quot;</td><td>236</td><td>79</td><td>1</td><td>23.3</td><td>3.5</td><td>0.5</td><td>3.0</td><td>0.0</td><td>1.0</td><td>31.3</td><td>2.5</td><td>0.0</td><td>0.638298</td></tr><tr><td>1</td><td>2024-01-01 00:36:38</td><td>2024-01-01 00:44:56</td><td>1</td><td>1.4</td><td>1</td><td>&quot;N&quot;</td><td>79</td><td>211</td><td>1</td><td>10.0</td><td>3.5</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>17.0</td><td>2.5</td><td>0.0</td><td>1.428571</td></tr><tr><td>1</td><td>2024-01-01 00:46:51</td><td>2024-01-01 00:52:57</td><td>1</td><td>0.8</td><td>1</td><td>&quot;N&quot;</td><td>211</td><td>148</td><td>1</td><td>7.9</td><td>3.5</td><td>0.5</td><td>3.2</td><td>0.0</td><td>1.0</td><td>16.1</td><td>2.5</td><td>0.0</td><td>4.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>2024-01-31 23:45:59</td><td>2024-01-31 23:54:36</td><td>null</td><td>3.18</td><td>null</td><td>null</td><td>107</td><td>263</td><td>0</td><td>15.77</td><td>0.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>1.0</td><td>21.77</td><td>null</td><td>null</td><td>0.628931</td></tr><tr><td>1</td><td>2024-01-31 23:13:07</td><td>2024-01-31 23:27:52</td><td>null</td><td>4.0</td><td>null</td><td>null</td><td>114</td><td>236</td><td>0</td><td>18.4</td><td>1.0</td><td>0.5</td><td>2.34</td><td>0.0</td><td>1.0</td><td>25.74</td><td>null</td><td>null</td><td>0.585</td></tr><tr><td>2</td><td>2024-01-31 23:19:00</td><td>2024-01-31 23:38:00</td><td>null</td><td>3.33</td><td>null</td><td>null</td><td>211</td><td>25</td><td>0</td><td>19.97</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.97</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>2</td><td>2024-01-31 23:07:23</td><td>2024-01-31 23:25:14</td><td>null</td><td>3.06</td><td>null</td><td>null</td><td>107</td><td>13</td><td>0</td><td>23.88</td><td>0.0</td><td>0.5</td><td>5.58</td><td>0.0</td><td>1.0</td><td>33.46</td><td>null</td><td>null</td><td>1.823529</td></tr><tr><td>1</td><td>2024-01-31 23:58:25</td><td>2024-02-01 00:13:30</td><td>null</td><td>8.1</td><td>null</td><td>null</td><td>138</td><td>75</td><td>0</td><td>32.4</td><td>7.75</td><td>0.5</td><td>7.29</td><td>6.94</td><td>1.0</td><td>55.88</td><td>null</td><td>null</td><td>0.9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_964_606, 20)\n",
       "┌──────────┬──────────────────────┬───────────────────────┬─────────────────┬───┬──────────────┬──────────────────────┬─────────────┬──────────────┐\n",
       "│ VendorID ┆ tpep_pickup_datetime ┆ tpep_dropoff_datetime ┆ passenger_count ┆ … ┆ total_amount ┆ congestion_surcharge ┆ Airport_fee ┆ tip_per_mile │\n",
       "│ ---      ┆ ---                  ┆ ---                   ┆ ---             ┆   ┆ ---          ┆ ---                  ┆ ---         ┆ ---          │\n",
       "│ i32      ┆ datetime[μs]         ┆ datetime[μs]          ┆ i64             ┆   ┆ f64          ┆ f64                  ┆ f64         ┆ f64          │\n",
       "╞══════════╪══════════════════════╪═══════════════════════╪═════════════════╪═══╪══════════════╪══════════════════════╪═════════════╪══════════════╡\n",
       "│ 2        ┆ 2024-01-01 00:57:55  ┆ 2024-01-01 01:17:43   ┆ 1               ┆ … ┆ 22.7         ┆ 2.5                  ┆ 0.0         ┆ 0.0          │\n",
       "│ 1        ┆ 2024-01-01 00:03:00  ┆ 2024-01-01 00:09:36   ┆ 1               ┆ … ┆ 18.75        ┆ 2.5                  ┆ 0.0         ┆ 2.083333     │\n",
       "│ 1        ┆ 2024-01-01 00:17:06  ┆ 2024-01-01 00:35:01   ┆ 1               ┆ … ┆ 31.3         ┆ 2.5                  ┆ 0.0         ┆ 0.638298     │\n",
       "│ 1        ┆ 2024-01-01 00:36:38  ┆ 2024-01-01 00:44:56   ┆ 1               ┆ … ┆ 17.0         ┆ 2.5                  ┆ 0.0         ┆ 1.428571     │\n",
       "│ 1        ┆ 2024-01-01 00:46:51  ┆ 2024-01-01 00:52:57   ┆ 1               ┆ … ┆ 16.1         ┆ 2.5                  ┆ 0.0         ┆ 4.0          │\n",
       "│ …        ┆ …                    ┆ …                     ┆ …               ┆ … ┆ …            ┆ …                    ┆ …           ┆ …            │\n",
       "│ 2        ┆ 2024-01-31 23:45:59  ┆ 2024-01-31 23:54:36   ┆ null            ┆ … ┆ 21.77        ┆ null                 ┆ null        ┆ 0.628931     │\n",
       "│ 1        ┆ 2024-01-31 23:13:07  ┆ 2024-01-31 23:27:52   ┆ null            ┆ … ┆ 25.74        ┆ null                 ┆ null        ┆ 0.585        │\n",
       "│ 2        ┆ 2024-01-31 23:19:00  ┆ 2024-01-31 23:38:00   ┆ null            ┆ … ┆ 23.97        ┆ null                 ┆ null        ┆ 0.0          │\n",
       "│ 2        ┆ 2024-01-31 23:07:23  ┆ 2024-01-31 23:25:14   ┆ null            ┆ … ┆ 33.46        ┆ null                 ┆ null        ┆ 1.823529     │\n",
       "│ 1        ┆ 2024-01-31 23:58:25  ┆ 2024-02-01 00:13:30   ┆ null            ┆ … ┆ 55.88        ┆ null                 ┆ null        ┆ 0.9          │\n",
       "└──────────┴──────────────────────┴───────────────────────┴─────────────────┴───┴──────────────┴──────────────────────┴─────────────┴──────────────┘"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.scan_iceberg(table).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c19386",
   "metadata": {},
   "source": [
    "Looking at the snapshots now, we see that the overwrite operation create 2 more snapshot, one for deleting the existing data, another for appending the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21e10325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>committed_at</th><th>snapshot_id</th><th>parent_id</th><th>operation</th><th>manifest_list</th><th>summary</th></tr><tr><td>datetime[ms]</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>list[struct[2]]</td></tr></thead><tbody><tr><td>2024-12-19 05:48:35.092</td><td>1266899188045554572</td><td>null</td><td>&quot;append&quot;</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-1266899188045554572-0-f40953b3-d76b-490e-8e14-3341ef82477c.avro&quot;</td><td>[{&quot;added-files-size&quot;,&quot;55387088&quot;}, {&quot;added-data-files&quot;,&quot;1&quot;}, … {&quot;total-equality-deletes&quot;,&quot;0&quot;}]</td></tr><tr><td>2024-12-19 05:55:41.703</td><td>4850976834413867788</td><td>1266899188045554572</td><td>&quot;delete&quot;</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-4850976834413867788-0-0a71ec8f-2671-42b8-8bce-ba6a14f5819e.avro&quot;</td><td>[{&quot;removed-files-size&quot;,&quot;55387088&quot;}, {&quot;deleted-data-files&quot;,&quot;1&quot;}, … {&quot;total-equality-deletes&quot;,&quot;0&quot;}]</td></tr><tr><td>2024-12-19 05:55:47.655</td><td>4394398071311520382</td><td>4850976834413867788</td><td>&quot;append&quot;</td><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-4394398071311520382-0-06a928c7-7e7b-4a8e-9b96-44269a1546ef.avro&quot;</td><td>[{&quot;added-files-size&quot;,&quot;59614012&quot;}, {&quot;added-data-files&quot;,&quot;1&quot;}, … {&quot;total-equality-deletes&quot;,&quot;0&quot;}]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 6)\n",
       "┌─────────────────────────┬─────────────────────┬─────────────────────┬───────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ committed_at            ┆ snapshot_id         ┆ parent_id           ┆ operation ┆ manifest_list                                                                                                                         ┆ summary                                                                                           │\n",
       "│ ---                     ┆ ---                 ┆ ---                 ┆ ---       ┆ ---                                                                                                                                   ┆ ---                                                                                               │\n",
       "│ datetime[ms]            ┆ i64                 ┆ i64                 ┆ str       ┆ str                                                                                                                                   ┆ list[struct[2]]                                                                                   │\n",
       "╞═════════════════════════╪═════════════════════╪═════════════════════╪═══════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
       "│ 2024-12-19 05:48:35.092 ┆ 1266899188045554572 ┆ null                ┆ append    ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-1266899188045554572-0-f40953b3-d76b-490e-8e14-3341ef82477c.avro ┆ [{\"added-files-size\",\"55387088\"}, {\"added-data-files\",\"1\"}, … {\"total-equality-deletes\",\"0\"}]     │\n",
       "│ 2024-12-19 05:55:41.703 ┆ 4850976834413867788 ┆ 1266899188045554572 ┆ delete    ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-4850976834413867788-0-0a71ec8f-2671-42b8-8bce-ba6a14f5819e.avro ┆ [{\"removed-files-size\",\"55387088\"}, {\"deleted-data-files\",\"1\"}, … {\"total-equality-deletes\",\"0\"}] │\n",
       "│ 2024-12-19 05:55:47.655 ┆ 4394398071311520382 ┆ 4850976834413867788 ┆ append    ┆ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/metadata/snap-4394398071311520382-0-06a928c7-7e7b-4a8e-9b96-44269a1546ef.avro ┆ [{\"added-files-size\",\"59614012\"}, {\"added-data-files\",\"1\"}, … {\"total-equality-deletes\",\"0\"}]     │\n",
       "└─────────────────────────┴─────────────────────┴─────────────────────┴───────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(table.inspect.snapshots())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284972f",
   "metadata": {},
   "source": [
    "Looking at the files for this table now, we see that a ne file has been created, in the started location that Iceberg will keep the data file, with the partitioning in the path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8f6e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>file_path</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/data/tpep_pickup_datetime_month=2024-01/00000-0-06a928c7-7e7b-4a8e-9b96-44269a1546ef.parquet&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│ file_path                                                                                                                                            │\n",
       "│ ---                                                                                                                                                  │\n",
       "│ str                                                                                                                                                  │\n",
       "╞══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
       "│ s3://warehouse/iceberg/nyc_taxi_data.db/yellow_tripdata/data/tpep_pickup_datetime_month=2024-01/00000-0-06a928c7-7e7b-4a8e-9b96-44269a1546ef.parquet │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.from_arrow(table.inspect.files()).select([\"file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c32fb",
   "metadata": {},
   "source": [
    "As the previous snapshots are still present, the original file we wrote to Minio is still present, just not attached to the current active snapshot. If were to run snapshot expiration operation (which is currently not supported though Pyiceberg), that original file would be deleted. In this way this workflow is different from the Hive external tables setup, where manipulation of the external tables in Hive does not affect the underlying files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273e911",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Here we show how to register parquet files to an iceberg table without having to rewrite it. This workflow can be useful in creating an Iceberg catalog layer on top of preexisting data, without costly rewrites. This could also go some way to addressing [Iceberg's portability problem](https://medium.com/@kkgsanjeewac77/curious-engineering-facts-icebergs-portability-get-rid-of-tokens-january-release-5-25-080325e6cd95), as we can use the `add_files` method to recreate the iceberg catalog, onces the files have been migrated to a new object storage, with the caveat that old snapshots are not migrated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
